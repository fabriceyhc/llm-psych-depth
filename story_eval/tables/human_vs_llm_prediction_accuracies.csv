model,human_binarized_accuracy,human_ordinal_accuracy,TechxGenus--Meta-Llama-3-8B-Instruct-GPTQ_binarized_accuracy,TechxGenus--Meta-Llama-3-8B-Instruct-GPTQ_ordinal_accuracy
Llama-2-7B,0.5125,0.5277777777777778,0.05555555555555555,0.07499999999999996
Llama-2-13B,0.6746987951807228,0.65,0.011235955056179775,0.0444444444444444
Vicuna-33B,0.6666666666666666,0.6666666666666667,0.013513513513513514,0.046666666666666634
Llama-2-70B,0.569620253164557,0.5777777777777777,0.0,0.036111111111111094
GPT-4,0.21951219512195122,0.27222222222222225,0.0,0.03888888888888886
Human-Novice,0.8571428571428571,0.7333333333333334,0.5714285714285714,0.6666666666666667
Human-Intermediate,0.9230769230769231,0.85,0.9333333333333333,0.8
Human-Advanced,0.9444444444444444,0.8,0.6470588235294118,0.6875
Human,0.9111111111111111,0.795,0.717391304347826,0.7150000000000001
LLM,0.5252525252525253,0.5344827586206897,0.01627906976744186,0.0482758620689655
Overall,0.564625850340136,0.561340206185567,0.08403361344537816,0.11701030927835054
