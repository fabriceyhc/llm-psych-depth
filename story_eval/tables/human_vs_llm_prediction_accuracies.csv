model,human_binarized_accuracy,human_ordinal_accuracy,Meta-Llama-3-70B-Instruct-f16_binarized_accuracy,Meta-Llama-3-70B-Instruct-f16_ordinal_accuracy
Llama-2-7B,0.5125,0.5277777777777778,0.17105263157894737,0.32499999999999996
Llama-2-13B,0.6746987951807228,0.65,0.125,0.30000000000000004
Vicuna-33B,0.6666666666666666,0.6666666666666667,0.1323529411764706,0.27
Llama-2-70B,0.569620253164557,0.5777777777777777,0.0625,0.2583333333333333
GPT-4,0.21951219512195122,0.27222222222222225,0.011627906976744186,0.14722222222222225
Human-Novice,0.8571428571428571,0.7333333333333334,0.7,0.5666666666666667
Human-Intermediate,0.9230769230769231,0.85,0.9230769230769231,0.7333333333333334
Human-Advanced,0.9444444444444444,0.8,1.0,0.8
Human,0.9111111111111111,0.795,0.8974358974358975,0.71
LLM,0.5252525252525253,0.5344827586206897,0.0968586387434555,0.2597701149425288
Overall,0.564625850340136,0.561340206185567,0.171021377672209,0.3061855670103093
