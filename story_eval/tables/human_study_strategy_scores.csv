model_short,strategy,authenticity_score,empathy_score,engagement_score,emotion_provoking_score,narrative_complexity_score,human_likeness_score
GPT-3.5,plan_write,2.275,2.3,2.025,2.225,2.025,2.05
GPT-3.5,writer_profile,2.525,2.4,2.5,2.4,2.35,2.325
GPT-4,plan_write,3.7291666666666665,3.4583333333333335,3.3541666666666665,3.3958333333333335,3.5208333333333335,3.5416666666666665
GPT-4,writer_profile,3.84,3.74,4.22,3.52,3.82,4.08
Llama-2-13B,plan_write,2.9183673469387754,2.795918367346939,2.4081632653061225,2.6122448979591835,2.4285714285714284,2.4081632653061225
Llama-2-13B,writer_profile,3.0408163265306123,2.7142857142857144,2.673469387755102,2.5510204081632653,2.4693877551020407,2.63265306122449
Llama-2-70B,plan_write,3.163265306122449,3.020408163265306,3.0408163265306123,2.9591836734693877,2.877551020408163,2.63265306122449
Llama-2-70B,writer_profile,2.9183673469387754,2.877551020408163,2.938775510204082,2.857142857142857,2.5306122448979593,2.8979591836734695
Llama-2-7B,plan_write,2.8181818181818183,2.727272727272727,2.590909090909091,2.840909090909091,2.5681818181818183,2.977272727272727
Llama-2-7B,writer_profile,3.0,2.54,2.86,2.42,2.34,2.76
Mixtral-8x7B,plan_write,2.55,2.6,2.35,2.4,2.425,2.325
Mixtral-8x7B,writer_profile,2.375,2.45,2.4,2.45,2.45,2.575
Vicuna-33B,plan_write,2.8125,2.6458333333333335,2.5625,2.5,2.6666666666666665,2.2916666666666665
Vicuna-33B,writer_profile,2.8461538461538463,2.7948717948717947,2.8205128205128207,2.7435897435897436,2.4871794871794872,2.5128205128205128
