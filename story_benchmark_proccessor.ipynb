{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf885ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2ceb0",
   "metadata": {},
   "source": [
    "# Combining from JSON \n",
    "NOTE: old way, we only use csv in this project now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "168ad9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_story_details = glob.glob(\"./data/v3/*/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2315576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_story(story_id):\n",
    "    if not isinstance(story_id, str):\n",
    "        return None\n",
    "    human_stories = glob.glob(\"./data/v3/*/*.md\")\n",
    "    path = [path for path in human_stories if story_id in path][0]\n",
    "    f = open(path, 'r', encoding=\"utf8\")\n",
    "    return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b747a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for path in human_story_details:\n",
    "    df = pd.read_json(path, encoding='utf-8').T\n",
    "    dfs.append(df)\n",
    "    \n",
    "human_df = pd.concat(dfs).reset_index().rename(columns={'index': 'key'})\n",
    "human_df = human_df[human_df[\"key\"] != \"gpt4\"]\n",
    "human_df[\"story_id\"] = human_df[\"url\"].str.extract('/comment/(\\w+)')\n",
    "human_df[\"text\"] = human_df[\"story_id\"].apply(fetch_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f32e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df.to_csv(\"./data/human_stories_2.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d9d05fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_df = pd.read_csv(\"./data/human_stories.csv\", encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56bc0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_stories = glob.glob(\"./llm_story_generation_results_v1/*/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7295612",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_map = {\n",
    "    \"meta-llama_Llama-2-7b-chat-hf\": \"Llama-2-7B\",  \n",
    "    \"meta-llama_Llama-2-13b-chat-hf\": \"Llama-2-13B\", \n",
    "    \"lmsys_vicuna-33b-v1.3\": \"Vicuna-33B\", \n",
    "    \"meta-llama_Llama-2-70b-chat-hf\": \"Llama-2-70B\",\n",
    "    \"gpt-4\": \"GPT-4\"    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dff73eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for path in llm_stories:\n",
    "    df = pd.read_json(path, typ='series').to_frame().T\n",
    "    df[\"strategy\"] = path.split(\"\\\\\")[-2]\n",
    "    df[\"story_id\"] = path.split(\"\\\\\")[-1].split(\"_\")[-1].replace(\".json\", \"\")\n",
    "    dfs.append(df)\n",
    "        \n",
    "llm_df = pd.concat(dfs)\n",
    "llm_df[\"model_short\"] = llm_df[\"model_name\"].apply(model_map.get)\n",
    "llm_df[\"characters\"] = llm_df[\"characters\"].str.strip()\n",
    "llm_df[\"output\"] = llm_df[\"output\"].str.strip()\n",
    "llm_df = llm_df.rename(columns={\n",
    "    \"output\": \"text\",\n",
    "    \"story_prompt\": \"prompt\"\n",
    "})\n",
    "llm_df = llm_df.drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7954d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_df.to_csv(\"./data/llm_stories_2.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9953d981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_name', 'prompt', 'characters', 'text', 'strategy', 'story_id',\n",
       "       'model_short'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1116b2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'url', 'net_upvotes', 'id', 'story_id', 'text'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad4f7d53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([human_df, llm_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08a73ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"./data/stories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc3f94-cb76-4a96-b3f4-2bea3055de32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e4703a-4d7b-4374-b365-5329c95ba3e8",
   "metadata": {},
   "source": [
    "# Cleaning bad formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a59844c4-4d7b-4cd7-a5a4-cb772cc48561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file with appropriate encoding\n",
    "file_path = './data/human_stories.csv'  # Update this path to your file location\n",
    "df = pd.read_csv(file_path, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6ce5014-621f-4faf-8925-54e1d65b17da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping of common misencoded characters to their likely intended ASCII counterparts\n",
    "replacement_map = {\n",
    "    'ý': \"'\",  # Assuming 'ý' was intended to be an apostrophe\n",
    "    '“': '\"',  # Opening curly quote to straight quote\n",
    "    '”': '\"',  # Closing curly quote to straight quote\n",
    "    '‘': \"'\",  # Opening single curly quote to straight apostrophe\n",
    "    '’': \"'\",  # Closing single curly quote to straight apostrophe\n",
    "    '—': '-',  # Em dash to hyphen\n",
    "    '–': '-'   # En dash to hyphen\n",
    "}\n",
    "\n",
    "# Function to replace characters based on the mapping\n",
    "def replace_characters(text, mapping):\n",
    "    for wrong, correct in mapping.items():\n",
    "        text = text.replace(wrong, correct)\n",
    "    return text\n",
    "\n",
    "# Apply the character replacements to the 'text' column\n",
    "df['text'] = df['text'].apply(lambda x: replace_characters(x, replacement_map))\n",
    "\n",
    "# Function to correct sequences of apostrophes that might represent double quotes or other misinterpretations\n",
    "def correct_sequences(text):\n",
    "    # Replace sequences of two or more apostrophes with double quotes\n",
    "    text = text.replace(\"''''''\", '\"')\n",
    "    text = text.replace(\"''''\", '\"')\n",
    "    text = text.replace(\"'''\", '\"')\n",
    "    return text\n",
    "\n",
    "# Apply the sequence corrections to the 'text' column\n",
    "df['text'] = df['text'].apply(correct_sequences)\n",
    "\n",
    "# # Optionally, save the cleaned data back to a CSV file\n",
    "# output_file_path = 'path_to_your_output_file.csv'  # Update this path to your desired output location\n",
    "# df.to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "# print(\"Data cleaning complete and saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "707242fa-bbf1-4f3b-a327-c67acbeb8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12abe497",
   "metadata": {},
   "source": [
    "# Retry Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daf68ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71140c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_profile_files = glob.glob(\"./llm_story_generation_results_retry_count_analysis/*writer_profile*.csv\")\n",
    "plan_write_files = glob.glob(\"./llm_story_generation_results_retry_count_analysis/*plan_write*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da0f77d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./llm_story_generation_results_retry_count_analysis\\stories_TheBloke.Llama-2-13B-chat-GPTQ_writer_profile.csv\n",
      "       length_retry_count  retry_count\n",
      "count           60.000000         60.0\n",
      "mean             9.483333          0.0\n",
      "std             14.735512          0.0\n",
      "min              0.000000          0.0\n",
      "25%              2.000000          0.0\n",
      "50%              5.000000          0.0\n",
      "75%             12.250000          0.0\n",
      "max            106.000000          0.0\n",
      "Average Length: 499.73333333333335\n",
      "./llm_story_generation_results_retry_count_analysis\\stories_TheBloke.Llama-2-70B-chat-GPTQ_writer_profile.csv\n",
      "       length_retry_count  retry_count\n",
      "count           60.000000         60.0\n",
      "mean             1.700000          0.0\n",
      "std              3.082482          0.0\n",
      "min              0.000000          0.0\n",
      "25%              0.000000          0.0\n",
      "50%              1.000000          0.0\n",
      "75%              2.000000          0.0\n",
      "max             19.000000          0.0\n",
      "Average Length: 529.65\n",
      "./llm_story_generation_results_retry_count_analysis\\stories_TheBloke.Llama-2-7B-chat-GPTQ_writer_profile.csv\n",
      "       length_retry_count  retry_count\n",
      "count           60.000000         60.0\n",
      "mean           138.500000          0.0\n",
      "std            143.131977          0.0\n",
      "min              4.000000          0.0\n",
      "25%             33.250000          0.0\n",
      "50%             88.000000          0.0\n",
      "75%            191.250000          0.0\n",
      "max            617.000000          0.0\n",
      "Average Length: 481.1\n",
      "./llm_story_generation_results_retry_count_analysis\\stories_TheBloke.Mixtral-8x7B-Instruct-v0.1-GPTQ_writer_profile.csv\n",
      "       length_retry_count  retry_count\n",
      "count           60.000000         60.0\n",
      "mean             0.183333          0.0\n",
      "std              0.469102          0.0\n",
      "min              0.000000          0.0\n",
      "25%              0.000000          0.0\n",
      "50%              0.000000          0.0\n",
      "75%              0.000000          0.0\n",
      "max              2.000000          0.0\n",
      "Average Length: 488.6\n",
      "./llm_story_generation_results_retry_count_analysis\\stories_lmsys.vicuna-33b-v1.3_plan_write.csv\n",
      "       characters_retry_count  length_retry_count  story_retry_count\n",
      "count               60.000000           60.000000               60.0\n",
      "mean                 0.500000            4.200000                0.0\n",
      "std                  0.770208            6.841548                0.0\n",
      "min                  0.000000            0.000000                0.0\n",
      "25%                  0.000000            1.000000                0.0\n",
      "50%                  0.000000            2.000000                0.0\n",
      "75%                  1.000000            5.250000                0.0\n",
      "max                  3.000000           46.000000                0.0\n",
      "Average Length: 503.6333333333333\n",
      "./llm_story_generation_results_retry_count_analysis\\stories_TheBloke.Llama-2-13B-chat-GPTQ_plan_write.csv\n",
      "       characters_retry_count  length_retry_count  story_retry_count\n",
      "count               60.000000           60.000000               60.0\n",
      "mean                 1.833333            5.266667                0.0\n",
      "std                  1.342483            5.439550                0.0\n",
      "min                  0.000000            0.000000                0.0\n",
      "25%                  0.000000            2.000000                0.0\n",
      "50%                  3.000000            4.000000                0.0\n",
      "75%                  3.000000            7.000000                0.0\n",
      "max                  3.000000           25.000000                0.0\n",
      "Average Length: 512.6833333333333\n",
      "./llm_story_generation_results_retry_count_analysis\\stories_TheBloke.Llama-2-70B-chat-GPTQ_plan_write.csv\n",
      "       characters_retry_count  length_retry_count  story_retry_count\n",
      "count               48.000000           48.000000               48.0\n",
      "mean                 1.833333            3.645833                0.0\n",
      "std                  1.310081            5.463572                0.0\n",
      "min                  0.000000            0.000000                0.0\n",
      "25%                  0.000000            0.000000                0.0\n",
      "50%                  2.500000            2.000000                0.0\n",
      "75%                  3.000000            5.000000                0.0\n",
      "max                  3.000000           31.000000                0.0\n",
      "Average Length: 547.375\n",
      "./llm_story_generation_results_retry_count_analysis\\stories_TheBloke.Llama-2-7B-chat-GPTQ_plan_write.csv\n",
      "       characters_retry_count  length_retry_count  story_retry_count\n",
      "count                    60.0           60.000000               60.0\n",
      "mean                      3.0           80.683333                0.0\n",
      "std                       0.0           92.922328                0.0\n",
      "min                       3.0            0.000000                0.0\n",
      "25%                       3.0           15.000000                0.0\n",
      "50%                       3.0           38.500000                0.0\n",
      "75%                       3.0          129.750000                0.0\n",
      "max                       3.0          438.000000                0.0\n",
      "Average Length: 495.5\n",
      "./llm_story_generation_results_retry_count_analysis\\stories_TheBloke.Mixtral-8x7B-Instruct-v0.1-GPTQ_plan_write.csv\n",
      "       characters_retry_count  length_retry_count  story_retry_count\n",
      "count               60.000000           60.000000               60.0\n",
      "mean                 0.383333            0.250000                0.0\n",
      "std                  0.640224            0.571202                0.0\n",
      "min                  0.000000            0.000000                0.0\n",
      "25%                  0.000000            0.000000                0.0\n",
      "50%                  0.000000            0.000000                0.0\n",
      "75%                  1.000000            0.000000                0.0\n",
      "max                  2.000000            3.000000                0.0\n",
      "Average Length: 476.6333333333333\n",
      "503.87870370370365\n"
     ]
    }
   ],
   "source": [
    "average_lengths = []\n",
    "for f in writer_profile_files + plan_write_files:\n",
    "    df = pd.read_csv(f)\n",
    "    cols = [c for c in df.columns if \"retry\" in c]\n",
    "    print(f)\n",
    "    print(df.describe()[cols])\n",
    "    average_length = df[\"text\"].str.split().str.len().mean()\n",
    "    average_lengths.append(average_length)\n",
    "    print(f\"Average Length: {average_length}\")\n",
    "\n",
    "print(np.mean(average_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8bf812",
   "metadata": {},
   "source": [
    "# Combining CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c44864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b0b5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = glob.glob(\"./llm_story_generation_results_v2/*.csv\")\n",
    "df = pd.concat((pd.read_csv(s) for s in stories))\n",
    "df.to_csv(\"data/llm_stories_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4984dede",
   "metadata": {},
   "source": [
    "# More cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5575c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean a single story\n",
    "def clean_story(story, strings_to_remove):\n",
    "    cleaned_lines = []\n",
    "    for line in story.split('\\n'):\n",
    "        stripped_line = line.strip()\n",
    "        if not any(stripped_line.startswith(s) for s in strings_to_remove):\n",
    "            cleaned_lines.append(stripped_line)\n",
    "    # Join the cleaned lines and then strip spaces and newlines from the entire text\n",
    "    cleaned_story = '\\n'.join(cleaned_lines).strip()\n",
    "    return cleaned_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58742d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file with appropriate encoding\n",
    "file_path = './data/llm_stories_v2.csv'  # Update this path to your file location\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6847c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_to_remove = [\n",
    "    \"```\", \"---\", \n",
    "    \"Title:\", \"**Title\", \n",
    "    \"Story:\", \"(Story)\", \"The Story:\", \"Story\", \"STORY\", \n",
    "    \"AI:\", \"AI-Sys\", \"AI Response\", \n",
    "    \"Computer:\", \"System:\", \"Assistant:\",\n",
    "    \"Human:\", \"Human Response:\", \"[You]\", \n",
    "    \"Input:\", \"Response:\", \n",
    "    \"Output:\", \"**Output\", \n",
    "    \"Answer:\", \n",
    "    \"Note:\",\n",
    "    \"ASSIGNMENT\",\n",
    "    \"Prompt\", \"Premise:\", \n",
    "    \"###\", \"**\", \n",
    "    \"No need for extra details\",\n",
    "    \"Do not provide any additional instructions\",\n",
    "    \"Just the story.\",\n",
    "    \"No comments or questions please.\"\n",
    "    \"No introduction or summary.\"\n",
    "    \"No greetings\",\n",
    "    \"No need to write any other details.\", \n",
    "    \"No introduction or summary needed.\",\n",
    "    \"No need for any additional information.\", \n",
    "    \"Ready to assist!\", \n",
    "    \"I have written the story below\",\n",
    "    \"Here is my attempt\",\n",
    "    \"Here is your story\",\n",
    "    \"Here is a 500-word story\", \n",
    "    \"Here is the story I wrote based on the prompt:\", \n",
    "    \"I understand that you want me to write a story based on the given prompt. Here's my response:\",\n",
    "    \"I have a lot of stories to read and I won't have time to read long comments. If you understand, just write the story.\",\n",
    "    \"No worries, I've got this covered! Here's the story:\", \n",
    "    \"Here's the story:\", \n",
    "    \"Here is the story:\", \n",
    "    \"Here's your story:\", \n",
    "    \"Here is your story: \",\n",
    "    \"And here is the story:\", \n",
    "    \"And here's the story:\", \n",
    "    \"Here is your 500 word story based on the prompt:\", \n",
    "    \"Here's my attempt at writing a 500-word story\", \n",
    "    \"Here's a possible story:\",\n",
    "    ]\n",
    "df['cleaned_text'] = df['text'].apply(lambda story: clean_story(story, strings_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80714d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/llm_stories_v2_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ab538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
